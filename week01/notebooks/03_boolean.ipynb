{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Boolean Search in Documents\n",
    "\n",
    "## Objective\n",
    "Expand the simple term search functionality to include Boolean search capabilities. This will allow users to perform more complex queries by combining multiple search terms using Boolean operators.\n",
    "\n",
    "## Problem Description\n",
    "You must enhance the existing search engine from the previous exercise to support Boolean operators: AND, OR, and NOT. This will enable the retrieval of documents based on the logical relationships between multiple terms.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "### Step 1: Update Data Preparation\n",
    "Ensure that the documents are still loaded and preprocessed from the previous task. The data should be clean and ready for advanced querying.\n",
    "\n",
    "### Step 2: Create an Inverted Index\n",
    "\n",
    "Create an inverted index from the documents. This index maps each word to the set of document IDs in which that word appears. This facilitates word lookup in the search process.\n",
    "\n",
    "### Step 3: Implementing Boolean Search\n",
    "- **Enhance Input Query**: Modify the function to accept complex queries that can include the Boolean operators AND, OR, and NOT.\n",
    "- **Implement Boolean Logic**:\n",
    "  - **AND**: The document must contain all the terms. For example, `python AND programming` should return documents containing both \"python\" and \"programming\".\n",
    "  - **OR**: The document can contain any of the terms. For example, `python OR programming` should return documents containing either \"python\", \"programming\", or both.\n",
    "  - **NOT**: The document must not contain the term following NOT. For example, `python NOT snake` should return documents that contain \"python\" but not \"snake\".\n",
    "\n",
    "### Step 4: Query Processing\n",
    "- **Parse the Query**: Implement a function to parse the input query to identify the terms and operators.\n",
    "- **Search Documents**: Based on the parsed query, implement the logic to retrieve and rank the documents according to the Boolean expressions.\n",
    "- **Handling Case Sensitivity and Partial Matches**: Optionally, you can handle cases and partial matches to refine the search results.\n",
    "\n",
    "### Step 5: Displaying Results\n",
    "- **Output the Results**: Display the documents that match the query criteria. Include functionalities to handle queries that result in no matching documents.\n",
    "\n",
    "## Evaluation Criteria\n",
    "- **Correctness**: The Boolean search implementation should correctly interpret and process the queries according to the Boolean logic.\n",
    "- **Efficiency**: Consider the efficiency of your search process, especially as the complexity of queries increases.\n",
    "- **User Experience**: Ensure that the interface for inputting queries and viewing results is user-friendly.\n",
    "\n",
    "## Additional Challenges (Optional)\n",
    "- **Nested Boolean Queries**: Allow for nested queries using parentheses, such as `(python OR java) AND programming`.\n",
    "- **Phrase Searching**: Implement the ability to search for exact phrases enclosed in quotes.\n",
    "- **Proximity Searching**: Extend the search to find terms that are within a specific distance from one another.\n",
    "\n",
    "This exercise will deepen your understanding of how search engines process and respond to complex user queries. By incorporating Boolean search, you not only enhance the functionality of your search engine but also mimic more closely how real-world information retrieval systems operate.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3678b6ceab34c216"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Excercise",
   "id": "10c46ac34b911bf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.816620Z",
     "start_time": "2024-04-30T20:44:34.810824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re"
   ],
   "id": "ed934b0248da2ce2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Same logic as in last excercise (02_boolean_basic)",
   "id": "68c0cecaa7ddf9b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.825807Z",
     "start_time": "2024-04-30T20:44:34.822517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIR = \"../data\"\n",
    "total_books = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
    "print(total_books)"
   ],
   "id": "5af01fb5b3f72862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.828973Z",
     "start_time": "2024-04-30T20:44:34.827181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ],
   "id": "23389e24d9698b8c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.831909Z",
     "start_time": "2024-04-30T20:44:34.830004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_book_content(book_path: str) -> str:\n",
    "    with open(f\"{DIR}/{book_path}\") as file:\n",
    "        book_content = file.read()\n",
    "        return book_content"
   ],
   "id": "be37ccd7f5daa8c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.835408Z",
     "start_time": "2024-04-30T20:44:34.833710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "punctuation_regex = r\"[^\\w\\s]\"\n",
    "books = []"
   ],
   "id": "80260033d8fc235a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.838588Z",
     "start_time": "2024-04-30T20:44:34.836395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_tokens(tokens: list[str]) -> list[str]:\n",
    "    normalized_tokens = [re.sub(punctuation_regex, \"\", str.lower()) for str in tokens]\n",
    "    return normalized_tokens"
   ],
   "id": "b7288f1616812655",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.872776Z",
     "start_time": "2024-04-30T20:44:34.870813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_input(input: str) -> list[str]:\n",
    "    tokens = normalize_tokens(input.split())\n",
    "    return tokens"
   ],
   "id": "b48c9a7303c56961",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.880568Z",
     "start_time": "2024-04-30T20:44:34.877981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_books() -> list[str]:\n",
    "    book_tokens = []\n",
    "    for i in range(1, total_books + 1):\n",
    "        book_path = f\"{DIR}/book{i}.txt\"\n",
    "        book_content = get_book_content(book_path).lower()\n",
    "        books.append(book_content)\n",
    "        book_tokens.append(tokenize_input(book_content))\n",
    "\n",
    "    return book_tokens"
   ],
   "id": "397b7583fc906f88",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:34.883746Z",
     "start_time": "2024-04-30T20:44:34.881877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = [\"\"]\n",
    "for i in range(1, total_books + 1):\n",
    "    rows.append(f\"book{i}\")"
   ],
   "id": "399700ff6adbed50",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:43.833909Z",
     "start_time": "2024-04-30T20:44:34.884271Z"
    }
   },
   "cell_type": "code",
   "source": "tokens = tokenize_books()",
   "id": "bea79bec11b0b499",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:45.963153Z",
     "start_time": "2024-04-30T20:44:43.836313Z"
    }
   },
   "cell_type": "code",
   "source": "unique_tokens = set(flatten(tokens))",
   "id": "8cfef9523d19d813",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T20:44:45.967569Z",
     "start_time": "2024-04-30T20:44:45.964588Z"
    }
   },
   "cell_type": "code",
   "source": "columns = [{\"token\": str, \"appereances\": list[int]}]",
   "id": "e983ff645f62491e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Same functionality as regular index with small change:\n",
    "\n",
    "In the appereances array we append the index of the book where the token is found "
   ],
   "id": "900a10dbe69e62b5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-30T20:44:45.969133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, token in enumerate(unique_tokens):\n",
    "    appereances = []\n",
    "    columns.append({\"token\": token, \"appereances\": appereances})\n",
    "    for i, book in enumerate(books):\n",
    "        if token in book:\n",
    "            appereances.append(i)\n",
    "            columns[index][\"appereances\"] = appereances\n",
    "\n",
    "inverted_index = {\"books\": rows, \"tokens\": columns}"
   ],
   "id": "7bab4accc61d45ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We print the results",
   "id": "89c32e2dfb4cb4ea"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(inverted_index[\"books\"]))\n",
    "print(inverted_index[\"books\"])"
   ],
   "id": "c487842f9782f491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(len(inverted_index[\"tokens\"]))",
   "id": "d0b83d1ecc1ee65d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(inverted_index[\"tokens\"])",
   "id": "e5878e7ae65af395",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
